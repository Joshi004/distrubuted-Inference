# ğŸ—ï¸ Distributed AI Inference Platform - System Architecture

## ğŸ“‹ Overview

The Distributed AI Inference Platform is a microservice-based system that provides AI inference capabilities as a service. The platform enables users to register, authenticate, and interact with AI models through both CLI and web interfaces.

**Key Characteristics:**
- **Microservice Architecture**: Loosely coupled workers handling specific domains
- **P2P Communication**: Workers communicate via RPC 
- **Event-Driven**: Asynchronous message passing between services
- **Secure**: JWT-based authentication with API key management

---

## ğŸ”„ System Request Flow

The system follows a clear request flow from frontend to backend:

1. **Frontend** (React Web UI) â†’ **Bridge Server** (HTTP/WebSocket interface)
2. **Bridge Server** â†’ **Client Worker** (Request orchestration)
3. **Client Worker** â†’ **Gateway Worker** (Authentication & routing)
4. **Gateway Worker** â†’ **Auth Worker** OR **Processor Worker** (based on request type)
5. **Processor Worker** â†’ **Ollama/Llama3** (AI inference)
6. Response flows back through the same chain

---

## ğŸ¯ Application Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND LAYER                           â”‚
â”‚                                                             â”‚
â”‚  ğŸŒ React Web UI              ğŸ’» CLI Interface              â”‚
â”‚  (Material-UI)                 (Interactive Tool)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                     â”‚
                  â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INTERFACE LAYER                            â”‚
â”‚                                                             â”‚
â”‚           ğŸŒ‰ Bridge Server          ğŸ‘¤ Client Worker        â”‚
â”‚         (HTTP/WebSocket)           (Request Orchestration)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                          â”‚
                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CORE BACKEND                              â”‚
â”‚                                                             â”‚
â”‚                ğŸšª Gateway Worker                            â”‚
â”‚            (Authentication & Routing)                      â”‚
â”‚                        â”‚                                   â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚        â–¼               â”‚               â–¼                   â”‚
â”‚  ğŸ” Auth Worker        â”‚        ğŸ¤– Processor Worker         â”‚
â”‚ (User Management)      â”‚       (AI Integration)            â”‚
â”‚                        â”‚               â”‚                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚               â–¼
                         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚    â”‚   EXTERNAL LAYER    â”‚
                         â”‚    â”‚                     â”‚
                         â”‚    â”‚  ğŸ§  Ollama/Llama3   â”‚
                         â”‚    â”‚   (AI Models)       â”‚
                         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    [Future: Other
                     Workers/Services]
```

**Request Flow:**
- **Authentication**: Web UI/CLI â†’ Bridge â†’ Client â†’ Gateway â†’ Auth Worker
- **AI Inference**: Web UI/CLI â†’ Bridge â†’ Client â†’ Gateway â†’ Processor â†’ Ollama

---

## ğŸ—ï¸ Core Components

### ğŸŒ Frontend Layer
- **React Web Application**: Modern UI built with Material-UI for user interactions
- **CLI Interface**: Command-line tool for developers and power users

### ğŸ”§ Interface Layer
- **Bridge Server**: HTTP/WebSocket server that connects web UI to backend workers
- **Client Worker**: Orchestrates requests and manages user sessions

### âš™ï¸ Core Backend Workers

#### ğŸšª Gateway Worker
- **Purpose**: Central routing and authentication hub
- **Responsibilities**:
  - Validates all incoming requests
  - Performs authentication and authorization
  - Routes requests to appropriate workers (Auth or Processor)
  - Applies rate limiting (future enhancement)
  - Tracks usage statistics (future enhancement)

#### ğŸ” Auth Worker  
- **Purpose**: User management and authentication
- **Responsibilities**:
  - User registration and login
  - JWT token generation and validation
  - API key management
  - User data persistence

#### ğŸ¤– Processor Worker
- **Purpose**: AI inference processing
- **Responsibilities**:
  - Processes AI prompts
  - Integrates with Ollama/Llama3 models
  - Handles model selection and configuration
  - Returns AI responses

---

## ğŸ“š Core Libraries

The system is built on three foundational libraries:

### 1. **bfx-wrk-base**
- Base worker framework providing common functionality
- RPC server/client implementation
- Lifecycle management (start, stop, restart)
- Facility management system

### 2. **hp-svc-facs-net** 
- P2P networking layer for inter-worker communication
- Handles service discovery and RPC calls
- Provides encrypted communication between workers

### 3. **hp-svc-facs-store**
- Distributed storage using Hyperbee
- Key-value storage for user data, sessions, and configurations
- Provides data persistence across worker restarts

---

## ğŸ”„ Authentication Flow

```
[User Login Request] â†’ [Bridge Server] â†’ [Client Worker] â†’ [Gateway Worker] 
                                                               â†“
[JWT Token Response] â† [Bridge Server] â† [Client Worker] â† [Auth Worker]
```

1. User submits credentials via web UI or CLI
2. Request flows through Bridge Server â†’ Client Worker â†’ Gateway Worker
3. Gateway Worker forwards to Auth Worker for validation
4. Auth Worker generates JWT token and returns response
5. Token flows back to user interface

---

## ğŸ”„ AI Inference Flow

```
[AI Prompt] â†’ [Bridge Server] â†’ [Client Worker] â†’ [Gateway Worker]
                                                       â†“
[AI Response] â† [Bridge Server] â† [Client Worker] â† [Processor Worker] â† [Ollama]
```

1. User submits AI prompt via interface
2. Gateway Worker validates authentication
3. Gateway Worker routes to Processor Worker
4. Processor Worker calls Ollama/Llama3 for inference
5. AI response flows back to user

---

## ğŸ“Š Supporting Services

### ğŸ“ Logging System
- **Centralized Logging**: All workers use shared logger
- **Structured Output**: JSON format for easy parsing
- **File-based Storage**: Logs written to `BackEnd/logs/`
  - `error.log` - Error messages and exceptions
  - `event.log` - General application events

### ğŸ“ˆ Metrics Collection
- **Prometheus Integration**: Standard metrics format
- **Worker-specific Metrics**: Each worker exposes metrics on different ports
  - Gateway: `http://localhost:9100/metrics`
  - Auth: `http://localhost:9101/metrics`
  - Processor: `http://localhost:9102/metrics`
- **System Metrics**: CPU, memory, request counters, response times

---

## ğŸ’¾ Data Storage

Each worker maintains its own data directory:
- `data/auth/` - User accounts, JWT tokens, API keys
- `data/client/` - Client sessions and preferences
- `data/gateway/` - Rate limiting and usage tracking data
- `data/processor/` - Model cache and request history

---

## ğŸš€ Future Enhancements

### Short-term Improvements
- **Enhanced Rate Limiting**: More comprehensive request throttling per user/API key
- **Advanced Usage Tracking**: Detailed analytics and quota management
- **Improved Security**: Replace static JWT secrets with dynamic key rotation and enhanced encryption

### Production Readiness
- **Docker Containerization**: Package workers as Docker containers
- **Kubernetes Deployment**: Orchestrate services using Kubernetes for scalability
- **Load Balancing**: Distribute requests across multiple worker instances

The system can be extended to support additional AI backends, more sophisticated caching mechanisms, and advanced monitoring dashboards as requirements evolve.

